{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a65d5344",
   "metadata": {},
   "source": [
    "## Décorateurs, Générateurs, Iterateurs, Async/Await en Python et plus encore !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de56bdd2",
   "metadata": {},
   "source": [
    "## Décorateurs (@)\n",
    "\n",
    "> Analogie : C'est comme amballer un cadeau (votre fonction originale) reste le meme, mais vous lui ajoutez du papier cadeau et un ruban (la nouvelle fonctionnalité)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec6de39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tache 'Nettoyage de données terminée !\n",
      "longue_operation a pris 2.001107692718506 secondes pour s'exécuter.\n"
     ]
    }
   ],
   "source": [
    "# Imaginons nous voulions mesurer le temps d\"exécution d'une fonction.\n",
    "import time\n",
    "\n",
    "def timer_decorateur(func):\n",
    "    # La fonction \"wrapper\" enveloppe la fonction originale\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs) # on exécute la fonction originale\n",
    "        end_time = time.time()\n",
    "        print(f\"{func.__name__} a pris {end_time - start_time} secondes pour s'exécuter.\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@timer_decorateur\n",
    "def longue_operation(nom_tache):\n",
    "    time.sleep(2)\n",
    "    print(f\"Tache '{nom_tache} terminée !\")\n",
    "    \n",
    "# on appelle simplement la fonction, le décorateur est déjà appliqué !\n",
    "longue_operation(\"Nettoyage de données\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6488f0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appel de la fonction 'addition'...\n",
      "Arguments positionnels (args): (3, 5)\n",
      "Arguments nommés (kwargs): {}\n",
      "La fonction 'addition' a retourné : 8\n",
      "Appel de la fonction 'saluer'...\n",
      "Arguments positionnels (args): ('Simone',)\n",
      "Arguments nommés (kwargs): {}\n",
      "La fonction 'saluer' a retourné : Bonjour, Simone !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Bonjour, Simone !'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Décorateur de journalisation (logging) : ce décorateur affiche des informations sur une focntion (ses arguments et sa valeur de retour) chaque fois qu'elle est appelée.\n",
    "def log_function_call(func):\n",
    "    # Affiche le nom de fonction, ses arguments et sa valeur de retour.\n",
    "    def wrapper(*args, **kwargs):\n",
    "        # avant l'appel de la fonction\n",
    "        print(f\"Appel de la fonction '{func.__name__}'...\")\n",
    "        print(f\"Arguments positionnels (args): {args}\")\n",
    "        print(f\"Arguments nommés (kwargs): {kwargs}\")\n",
    "        \n",
    "        # Appel de la fonction originale\n",
    "        result = func(*args, **kwargs)\n",
    "        \n",
    "        # Aprés l'appel de la fonction\n",
    "        print(f\"La fonction '{func.__name__}' a retourné : {result}\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@log_function_call\n",
    "def addition(a, b):\n",
    "    return a+b\n",
    "\n",
    "@log_function_call\n",
    "def saluer(nom, message=\"Bonjour\"):\n",
    "    return f\"{message}, {nom} !\"\n",
    "\n",
    "# utilisation\n",
    "addition(3,5)\n",
    "saluer(\"Simone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dff7d6",
   "metadata": {},
   "source": [
    "## Les Générateurs (yield)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "899a2e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Générateur\n",
      "<generator object generateur_carres at 0x00000285DB908110>\n",
      "0\n",
      "1\n",
      "4\n",
      "Reste des valeurs :\n",
      "9\n",
      "16\n",
      "25\n",
      "36\n",
      "49\n",
      "64\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "# Fonction classique (gourmande en mémoire pour de grandes listes)\n",
    "def liste_carres(n):\n",
    "    resultats = []\n",
    "    for i in range(n):\n",
    "        resultats.append(i * i)\n",
    "    return resultats\n",
    "\n",
    "# Générateur (très efficace en mémoire)\n",
    "def generateur_carres(n):\n",
    "    for i in range(n):\n",
    "        yield i * i # 'yield' met en pause et \"retourne une valeur\"\n",
    "        \n",
    "# use case\n",
    "print(\"Générateur\")\n",
    "# 'gen' est un objet générateur, rien n'a encore été calculé\n",
    "gen = generateur_carres(10)\n",
    "print(gen)\n",
    "\n",
    "# on consommme les valeurs une par une\n",
    "print(next(gen)) # Affiche 0\n",
    "print(next(gen)) # Affiche 1\n",
    "print(next(gen)) # Affiche 4\n",
    "\n",
    "# on peut aussi l'utiliser directement dans une boucle for\n",
    "print(\"Reste des valeurs :\")\n",
    "for carre in gen:\n",
    "    print(carre) # 9 16 etc...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1367a16b",
   "metadata": {},
   "source": [
    "> Un générateur est une fonction qui ne retourne pas une valeur unique, mais une séquence de valeurs à la demande, en utilisant le mot-clé yield.\n",
    "Contrairement à une fonction classique qui retourne un résultat et termine, un générateur se met en pause après chaque yield et reprends là où il s’était arrêté quand on lui demande la valeur suivante.\n",
    "\n",
    "## Comparaison entre une liste et un générateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74ac1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une liste avec 1 million de nombres\n",
    "grande_liste = liste_carres(1000000) # consomme beaucoup de mémoire (RAM)  IMPORTANT : NE PAS EXECUTER CETTE CELLULE SI VOUS AVEZ PEU DE RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3d40e3",
   "metadata": {},
   "source": [
    "Problème :\n",
    "\n",
    "- La liste occupe beaucoup de mémoire (environ 8 Mo pour 1 million d’entiers).\n",
    "- Si tu ne traites qu’un élément à la fois, c’est du gaspillage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c206a96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Avec un générateur, on peut traiter les nombres un par un sans tout stocker en mémoire\n",
    "def generate_nombres(n):\n",
    "    for i in range(n):\n",
    "        yield i # 'yield' met en pause et \"retourne une valeur\"\n",
    "        \n",
    "nombre = generate_nombres(1000000) # ici pas de liste en mémoire, juste un générateur créé\n",
    "for _ in range(10): # on traite les 10 premiers nombres\n",
    "    print(next(nombre)) # affiche les nombres de 0 à 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcfaee6",
   "metadata": {},
   "source": [
    "Avantages :\n",
    "\n",
    "- Pas de stockage en mémoire : Les nombres sont générés à la volée.\n",
    "- Économie de mémoire : Seul le nombre courant est en mémoire.\n",
    "- Traitement immédiat : Pas besoin d’attendre que tout soit généré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4679d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Traitement \"Lazy\" (paresseux)\n",
    "# Les données sont générées uniquement quand on en a besoin.\n",
    "def lire_gros_fichier(fichier):\n",
    "    with open(fichier, 'r') as f:\n",
    "        for ligne in f:  # ⬅️ Générateur implicite !\n",
    "            yield ligne\n",
    "\n",
    "for ligne in lire_gros_fichier(\"huge_file.txt\"):\n",
    "    print(ligne)  # Traite une ligne à la fois"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af740e88",
   "metadata": {},
   "source": [
    "### Exemple Avancé : Pipeline de données avec des génréteurs\n",
    "\n",
    "> Alors, imaginons que nous ayons une flux de données brutes (ventes, logs, etc...) et nous voulons les nettoyer, les filtrer et les transformer, le tout sans jamais rien stocker en mémoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "688a277b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation des données...\n",
      "Filtrage des données avec un seuil de quantité > 10...\n",
      "Début du nettoyage des données...\n",
      "Donnée filtrée (quantité insuffisante) : Pomme avec quantité 10\n",
      "Donnée invalide ignorée : {'id': 2, 'produit': 'Orange', 'quantite': 'cinq'}\n",
      "{'ID Produit': 3, 'Nom Produit': 'Banane', 'Quantité en Stock': 150, 'Statut': 'En Stock'}\n",
      "Donnée filtrée (quantité insuffisante) : Poire avec quantité 8\n",
      "{'ID Produit': 5, 'Nom Produit': 'Fraise', 'Quantité en Stock': 200, 'Statut': 'En Stock'}\n",
      "{'ID Produit': 6, 'Nom Produit': 'Raisin', 'Quantité en Stock': 50, 'Statut': 'En Stock'}\n",
      "{'ID Produit': 7, 'Nom Produit': 'Melon', 'Quantité en Stock': 12, 'Statut': 'En Stock'}\n",
      "Donnée invalide ignorée : {'id': 9, 'produit': 'Kiwi', 'quantite': 'douze'}\n",
      "{'ID Produit': 10, 'Nom Produit': 'Mangue', 'Quantité en Stock': 30, 'Statut': 'En Stock'}\n",
      "Donnée invalide ignorée : {'id': 11, 'produit': 'Cerise', 'quantite': None}\n",
      "Donnée filtrée (quantité insuffisante) : Ananas avec quantité 0\n",
      "{'ID Produit': 13, 'Nom Produit': 'Poire', 'Quantité en Stock': 15, 'Statut': 'En Stock'}\n"
     ]
    }
   ],
   "source": [
    "# Nos données sources simulées\n",
    "\n",
    "donnees_brutes = [\n",
    "    {\"id\": 1, \"produit\": \"Pomme\", \"quantite\": 10},\n",
    "    {\"id\": 2, \"produit\": \"Orange\", \"quantite\": \"cinq\"}, # Donnée invalide\n",
    "    {\"id\": 3, \"produit\": \"Banane\", \"quantite\": 150},\n",
    "    {\"id\": 4, \"produit\": \"Poire\", \"quantite\": 8},\n",
    "    {\"id\": 5, \"produit\": \"Fraise\", \"quantite\": 200},\n",
    "    {\"id\": 6, \"produit\": \"Raisin\", \"quantite\": 50},\n",
    "    {\"id\": 7, \"produit\": \"Melon\", \"quantite\": 12},\n",
    "    {\"id\": 8, \"produit\": \"Abricot\", \"quantite\": -5},            # quantite négative (invalide)\n",
    "    {\"id\": 9, \"produit\": \"Kiwi\", \"quantite\": \"douze\"},         # quantite en chaîne (invalide)\n",
    "    {\"id\": 10, \"produit\": \"Mangue\", \"quantite\": 30},\n",
    "    {\"id\": 11, \"produit\": \"Cerise\", \"quantite\": None},         # valeur manquante (invalide)\n",
    "    {\"id\": 12, \"produit\": \"Ananas\"},                           # clé quantite manquante (invalide)\n",
    "    {\"id\": 13, \"produit\": \"  Poire  \", \"quantite\": \"15\"},      # espaces et quantite en chaîne (à normaliser)\n",
    "]\n",
    "\n",
    "# Étape 1 : Nettoyage des données, premier générateur\n",
    "def nettoyer_donnees(donnees):\n",
    "    # générateur qui nettoie les données\n",
    "    print(\"Début du nettoyage des données...\")\n",
    "    for item in donnees:\n",
    "        try:\n",
    "            quantite = int(item.get(\"quantite\", 0)) # Convertir en entier, défaut à 0 si manquant\n",
    "            if quantite < 0:\n",
    "                continue  # Ignorer les quantités négatives\n",
    "            item[\"quantite\"] = quantite # Mettre à jour la quantité nettoyée\n",
    "            item[\"produit\"] = item[\"produit\"].strip().title()  # Normaliser le nom du produit\n",
    "            yield item # ne produit l'item si il est valide\n",
    "        except (ValueError, TypeError):\n",
    "            print(f\"Donnée invalide ignorée : {item}\")\n",
    "            continue  # Ignorer les entrées avec des quantités non convertibles\n",
    "        \n",
    "# Étape 2 : Filtrage des données, deuxième générateur\n",
    "def filtrer_donnees(donnees, seuil_quantite):\n",
    "    print(f\"Filtrage des données avec un seuil de quantité > {seuil_quantite}...\")\n",
    "    for item in donnees:\n",
    "        if item[\"quantite\"] > seuil_quantite:\n",
    "            yield item\n",
    "        else:\n",
    "            print(f\"Donnée filtrée (quantité insuffisante) : {item['produit']} avec quantité {item['quantite']}\")\n",
    "\n",
    "# Étape 3 : Transformation des données, troisième générateur\n",
    "def transformer_donnees(donnees):\n",
    "    print(\"Transformation des données...\")\n",
    "    for item in donnees:\n",
    "        item_transforme = {\n",
    "            \"ID Produit\": item[\"id\"],\n",
    "            \"Nom Produit\": item[\"produit\"],\n",
    "            \"Quantité en Stock\": item[\"quantite\"],\n",
    "            \"Statut\": \"En Stock\" if item[\"quantite\"] > 0 else \"Rupture de Stock\"\n",
    "        }\n",
    "        yield item_transforme\n",
    "    \n",
    "# Pipeline complet\n",
    "pipeline = transformer_donnees(\n",
    "    filtrer_donnees(\n",
    "        nettoyer_donnees(donnees_brutes),\n",
    "        seuil_quantite=10\n",
    "    )\n",
    ")\n",
    "\n",
    "# Consommation du pipeline\n",
    "for produit in pipeline:\n",
    "    print(produit)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cbbefb",
   "metadata": {},
   "source": [
    "## Generator expression(Expression genératrice)\n",
    "\n",
    "- List Comprehension (Crée une liste complète en mémoire) : Vous connaissez cette syntaxe qui utilise des crochets [] :\n",
    "```python\n",
    "squares = [x**2 for x in range(10)]\n",
    "```\n",
    "- Generator Expression (Crée un générateur qui produit des éléments à la demande) : Utilise des parenthèses () au lieu de crochets [] :\n",
    "```python\n",
    "squares_gen = (x**2 for x in range(10))\n",
    "```\n",
    "Avantages des Generator Expressions :\n",
    "- Efficacité Mémoire (Lazy Evaluation) : L'expression génératrice ne calcule les valeurs qu'au moment où vous les demandez (par exemple, dans une boucle for). Elle ne stocke jamais toute la collection en mémoire. C'est exactement le même principe que les générateurs créés avec yield.\n",
    "\n",
    "- Performance : C'est beaucoup plus rapide à démarrer car Python n'a pas besoin d'allouer de la mémoire pour des millions d'éléments d'un coup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662fbefb",
   "metadata": {},
   "source": [
    "## cas d'utilisation par exemple\n",
    "Utiliser une expression génératrice partout où vous avez besoin de parcourir une séquence une seule fois, sans avoir besoin de la stocker. C'est très courant dans les fonctions d'agrégation.\n",
    "\n",
    "Exemple : Imaginez que vous vouliez la somme des carrés de 10 millions de nombres.\n",
    "\n",
    "Mauvaise façon (inefficace) :\n",
    "```python\n",
    "# 1. Crée une liste de 10 millions d'éléments en mémoire\n",
    "# 2. Puis la parcourt pour faire la somme\n",
    "squares = [x**2 for x in range(10000000)]\n",
    "total = sum(squares)\n",
    "```\n",
    "\n",
    "Bonne façon (efficace) :\n",
    "```python\n",
    "'sum()' va \"tirer\" les valeurs du générateur une par une\n",
    "# et les additionner sans jamais créer la liste complète.\n",
    "somme = sum(x * x for x in range(10_000_000))\n",
    "# (Notez qu'on peut même omettre les parenthèses ()\n",
    "# quand l'expression est le seul argument d'une fonction)\n",
    "\n",
    "En résumé : Une expression génératrice est à un générateur ce qu'une \"list comprehension\" est à une liste. C'est un raccourci syntaxique pour créer des générateurs simples en une seule ligne."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3a01ac",
   "metadata": {},
   "source": [
    "### Exemple d'un generator pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7371e533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[118, 114, 128, 118, 120, 123, 128]\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    \"zoo length wrong shinning mathematics shoulder stage example weak roll found evidence species born grain further offer whose stay rope provide everyone ice pound\",\n",
    "    \"peace forty almost myself pride roar disappear harbor contain nest expression lost cost happy select jack leader cloth physical farmer rising army every element\",\n",
    "    \"onto oxygen thick process until thin feathers personal fruit worse yes eat shot poet feet tales beneath steam thread know you worry best herd\",\n",
    "    \"tall serious creature weather close lie grabbed orange past radio chose fact cow public act perfect dirty pot cup was cake cap fix secret\",\n",
    "    \"hunter elephant kids against thought becoming source those prevent behind solution suddenly wolf duck long construction thou information closely letter together wet distant show\",\n",
    "    \"lonely bow dead effort pleasure arrange dirty torn series what speech individual congress yes solution came daughter throughout business gather come learn cow using\",\n",
    "    \"fact thy properly talk statement tropical education serve composed parent unit die door older pull should by almost blue weak found primitive oil pleasure\",\n",
    "    \"breath wind unless sister scared sudden selection neighbor direction ground tropical hurt fell us furniture right card shinning guard than paid lion you quietly\",\n",
    "    \"round chain act forget trouble magic angry now instance command are queen bowl captain work deep underline vote also foreign service struggle managed complex\",\n",
    "    \"favorite mood student mouth wall event settle compound chamber stream floor power season tightly happy require sang radio else ago young rapidly damage clear\",\n",
    "    \"hole explain handle early here bush nest cotton does angle clearly wind fruit slightly wrong signal sink needle exact island face married party general\",\n",
    "    \"moon frequently complete essential deep complex way dead lot amount lesson grown pride meat knowledge score remove nearly ever tonight automobile decide us won\",\n",
    "    \"wood could press wife lay ten blow area dug mental pale glass clothes board six anybody everything apart will other pride ran straight living\",\n",
    "    \"vessels excellent traffic pupil choose jungle supply slight trap animal simplest burst same forty fighting away truth sit ill weigh former familiar eaten common\",\n",
    "    \"silver case ahead barn whispered kind from breath cave fill forest addition cat manner train children greater accept unusual television but jack fighting went\",\n",
    "    \"attack correctly getting tune think joined bent shoulder according roof swept yes managed visit harder particles pole feet yourself knew warn plates ourselves brown\",\n",
    "    \"stomach seldom trail pure tool river captured gray farm she equator fight row laid observe flat better look brass cool different why book south\",\n",
    "    \"metal church string alphabet nearly number record depth outline remain for where sugar arrange twenty poet struggle body particular after tell mix agree scientific\",\n",
    "    \"peace mass forty colony dress it shelter sides printed shout pupil energy law nature also person lake chance drawn noon though crop meant although\",\n",
    "    \"dull recent road tone ask exercise almost rice tried log environment part circle enemy seen business parts own stretch problem classroom win done glass\",\n",
    "]\n",
    "\n",
    "\n",
    "strip_ws = [0] # generator expression removing the spaces from the strings\n",
    "len_str = [0] # generator expression finding each string's length\n",
    "less_than = [0] # generator expression all the lengths less than 130\n",
    "\n",
    "# creating the generator expressions\n",
    "strip_ws = (s.replace(\" \", \"\") for s in data)\n",
    "len_str = (len(s) for s in strip_ws)\n",
    "less_than = (l for l in len_str if l < 130)\n",
    "# consuming the final generator\n",
    "# for length in less_than:\n",
    "#     print(length)\n",
    "\n",
    "print(list(less_than))\n",
    "# NOTE the first and second to print out the result of the generator cannot be used at the same time because the first one will have already consumed the generator.\n",
    "    \n",
    "# or\n",
    "# print(list(l for l in (len(s.replace(\" \", \"\")) for s in data) if l < 130))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4719ec12",
   "metadata": {},
   "source": [
    "Here, we are going to use a generator to clean a wheather API response. \n",
    "- Create a function called clean_data that takes a list of dictionaries as input.\n",
    "- The functions should clean the data so that temps is an interger, the data becomes a DateTime object, the wind_speed is a float. \n",
    "- Country is already in lowercase.\n",
    "- The function return a generator that yields cleaned dictionaries one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68b741fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country': 'somalia', 'temp': 88, 'date': datetime.datetime(2046, 4, 5, 0, 0), 'wind_speed': 23.64}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "data = [{\"country\": \"Somalia\",\"temp\": \"88\",\"date\": \"4/5/2046\",\"wind_speed\": \"23.64mph\",},]\n",
    "\n",
    "def clean_data(data):\n",
    "    for weather_data in data:\n",
    "        cleaned_data = {}\n",
    "        cleaned_data[\"country\"] = weather_data[\"country\"].lower()\n",
    "        cleaned_data[\"temp\"] = int(weather_data[\"temp\"])\n",
    "        cleaned_data[\"date\"] = datetime.strptime(weather_data[\"date\"], \"%m/%d/%Y\")\n",
    "        cleaned_data[\"wind_speed\"] = float(weather_data[\"wind_speed\"].replace(\"mph\", \"\"))\n",
    "        yield cleaned_data\n",
    "        \n",
    "# usage\n",
    "for cleaned in clean_data(data):\n",
    "    print(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2142c3",
   "metadata": {},
   "source": [
    "## Programmation Asynchrone (async/await)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00d8c266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Démarrage du pipeline de données asynchrone ---\n",
      "Étape 1 : Récupération de la liste des catégories...\n",
      "\n",
      "Étape 1 terminée. 4 catégories trouvées : ['electronics', 'jewelery', \"men's clothing\", \"women's clothing\"]\n",
      "\n",
      "--- ÉTAPE 2 : Lancement des tâches en parallèle ---\n",
      "  -> Tâche créée pour la catégorie 'electronics'\n",
      "  -> Tâche créée pour la catégorie 'jewelery'\n",
      "  -> Tâche créée pour la catégorie 'men's clothing'\n",
      "  -> Tâche créée pour la catégorie 'women's clothing'\n",
      "\n",
      "--- ÉTAPE 3 : Traitement des résultats ---\n",
      "Catégorie 'electronics': 6 produits trouvés.\n",
      "Catégorie 'jewelery': 4 produits trouvés.\n",
      "Catégorie 'men's clothing': 4 produits trouvés.\n",
      "Catégorie 'women's clothing': 6 produits trouvés.\n",
      "\n",
      "--- RÉSUMÉ ---\n",
      "Nombre total de produits récupérés : 20\n",
      "Temps total : 0.29 secondes\n",
      "\n",
      "Exemple de données (premier produit de la première catégorie) :\n",
      "{'category': 'electronics',\n",
      " 'description': 'USB 3.0 and USB 2.0 Compatibility Fast data transfers Improve '\n",
      "                'PC Performance High Capacity; Compatibility Formatted NTFS '\n",
      "                'for Windows 10, Windows 8.1, Windows 7; Reformatting may be '\n",
      "                'required for other operating systems; Compatibility may vary '\n",
      "                'depending on user’s hardware configuration and operating '\n",
      "                'system',\n",
      " 'id': 9,\n",
      " 'image': 'https://fakestoreapi.com/img/61IBBVJvSDL._AC_SY879_t.png',\n",
      " 'price': 64,\n",
      " 'rating': {'count': 203, 'rate': 3.3},\n",
      " 'title': 'WD 2TB Elements Portable External Hard Drive - USB 3.0 '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wamba\\AppData\\Local\\Temp\\ipykernel_27028\\2066890320.py:109: RuntimeWarning: coroutine 'main' was never awaited\n",
      "  asyncio.get_event_loop().run_until_complete(main())\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import time\n",
    "import pprint # pour une affiche plus \"joli\" des dictionnaires\n",
    "\n",
    "# URL de base de l'API publique \n",
    "BASE_URL = \"https://fakestoreapi.com\"\n",
    "\n",
    "async def fetch_json(session: aiohttp.ClientSession, url: str) -> dict | list | None:\n",
    "    # Une coroutine utilitaire pour récupérer les données JSON d'une URL et gérer les erreurs de base.\n",
    "    try:\n",
    "        async with session.get(url) as response:\n",
    "            response.raise_for_status() # lève une erreur pour les status 4xx/5xx\n",
    "            # 'await' ici met cette coroutine en pause, permettant aux autres de s'exécuter\n",
    "            data = await response.json()\n",
    "            return data\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lirs de la requete vers {url}: {e}\")\n",
    "        return None\n",
    "    \n",
    "async def get_categories(session: aiohttp.ClientSession) -> list:\n",
    "    \"\"\"\n",
    "    Étape 1 : Récupérer la liste des noms de catégories.\n",
    "    \"\"\"\n",
    "    print(\"Étape 1 : Récupération de la liste des catégories...\")\n",
    "    url = f\"{BASE_URL}/products/categories\"\n",
    "    categories = await fetch_json(session, url)\n",
    "    return categories if categories else []\n",
    "\n",
    "async def get_products_in_category(session: aiohttp.ClientSession, category: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Étape 2 : Récupérer tous les produits pour UNE catégorie donnée.\n",
    "    Retourne un tuple (nom_categorie, liste_produits)\n",
    "    \"\"\"\n",
    "    print(f\"  -> Tâche créée pour la catégorie '{category}'\")\n",
    "    url = f\"{BASE_URL}/products/category/{category}\"\n",
    "    products = await fetch_json(session, url)\n",
    "    return (category, products if products else [])\n",
    "\n",
    "async def main():\n",
    "    \"\"\"\n",
    "    La coroutine principale qui orchestre le pipeline.\n",
    "    \"\"\"\n",
    "    print(\"--- Démarrage du pipeline de données asynchrone ---\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Créer une seule session pour toutes nos requêtes\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        \n",
    "        # --- ÉTAPE 1 : Appel unique et bloquant (dans 'main') ---\n",
    "        # Nous avons besoin des catégories avant de pouvoir continuer,\n",
    "        # donc nous utilisons 'await' ici.\n",
    "        categories = await get_categories(session)\n",
    "        \n",
    "        if not categories:\n",
    "            print(\"Impossible de récupérer les catégories. Arrêt.\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\nÉtape 1 terminée. {len(categories)} catégories trouvées : {categories}\")\n",
    "        print(\"\\n--- ÉTAPE 2 : Lancement des tâches en parallèle ---\")\n",
    "\n",
    "        # --- ÉTAPE 2 : Création de la liste des tâches concurrentes ---\n",
    "        # Nous ne les 'await' PAS encore. Nous créons juste les \"promesses\".\n",
    "        tasks = []\n",
    "        for category_name in categories:\n",
    "            task = get_products_in_category(session, category_name)\n",
    "            tasks.append(task)\n",
    "            \n",
    "        # --- ÉTAPE 3 : Exécution de toutes les tâches en parallèle ---\n",
    "        # asyncio.gather() lance toutes les tâches dans 'tasks'\n",
    "        # et attend qu'elles soient TOUTES terminées.\n",
    "        # return_exceptions=True empêche le programme de planter si UNE seule requête échoue.\n",
    "        results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "        \n",
    "    end_time = time.time()\n",
    "    print(\"\\n--- ÉTAPE 3 : Traitement des résultats ---\")\n",
    "\n",
    "    total_products = 0\n",
    "    for res in results:\n",
    "        if isinstance(res, Exception):\n",
    "            # Si une des tâches a échoué, on l'affiche\n",
    "            print(f\"Échec de la récupération d'une catégorie : {res}\")\n",
    "        else:\n",
    "            # Sinon, on traite le résultat (category, products)\n",
    "            category_name, products = res\n",
    "            print(f\"Catégorie '{category_name}': {len(products)} produits trouvés.\")\n",
    "            total_products += len(products)\n",
    "            \n",
    "    print(\"\\n--- RÉSUMÉ ---\")\n",
    "    print(f\"Nombre total de produits récupérés : {total_products}\")\n",
    "    print(f\"Temps total : {end_time - start_time:.2f} secondes\")\n",
    "    \n",
    "    # Affichons un exemple de données reçues\n",
    "    if results and not isinstance(results[0], Exception):\n",
    "        print(\"\\nExemple de données (premier produit de la première catégorie) :\")\n",
    "        pprint.pprint(results[0][1][0])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Si c'était synchrone, le temps total serait la somme de tous les appels.\n",
    "    # En asynchrone, le temps total sera (temps étape 1) + (temps du plus long appel de l'étape 2).\n",
    "    try:\n",
    "        asyncio.run(main())\n",
    "    except RuntimeError:\n",
    "        # Probablement déjà dans une boucle d'événements (ex: Jupyter Notebook).\n",
    "        # Tenter d'utiliser nest_asyncio pour permettre l'imbrication des boucles d'événements.\n",
    "        try:\n",
    "            import nest_asyncio\n",
    "            nest_asyncio.apply()\n",
    "            asyncio.get_event_loop().run_until_complete(main())\n",
    "        except ImportError:\n",
    "            print(\"Le package 'nest_asyncio' est requis pour exécuter asyncio.run() dans ce contexte.\")\n",
    "            print(\"Installez-le avec : %pip install nest_asyncio\")\n",
    "            raise\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
